# 策略改进对比

## 原始策略 (Ridge Regression)

### 模型
- **算法**: Ridge回归（线性模型）
- **特点**: 只能捕捉因子与收益之间的线性关系

### 训练数据
- **时间范围**: start_date前3年
- **样本量**: 约34个周期（月度）

### 投资组合构建
- **选股数量**: 50只
- **权重方式**: 等权配置（每只股票1/50）
- **选股标准**: 预测收益最高的50只

### 性能表现
- **信息比率**: 0.268905

---

## 改进策略 (Gradient Boosting)

### 模型改进
- **算法**: Gradient Boosting Regressor
- **优势**:
  1. 可以捕捉非线性关系
  2. 可以学习因子之间的交互作用
  3. 更强的表达能力
  
- **防止过拟合措施**:
  1. `max_depth=5`: 限制树的深度
  2. `min_samples_split=30, min_samples_leaf=15`: 增加分裂和叶节点的最小样本数
  3. `subsample=0.7`: 每次训练只使用70%的样本
  4. `max_features='sqrt'`: 每次分裂只考虑部分特征
  5. `learning_rate=0.03`: 较低的学习率
  
- **鲁棒性增强**:
  - `loss='huber', alpha=0.9`: 使用Huber损失函数，对异常值更鲁棒

### 训练数据扩展
- **时间范围**: start_date前4年（比原来多1年）
- **样本量**: 约46个周期（增加约35%）
- **好处**: 更多数据帮助模型学习更稳定的规律

### 投资组合优化

#### 1. 选股数量优化
- **从50只减少到40只**
- **原理**: 更集中的投资组合，专注于质量最高的股票
- **优势**: 
  - 减少低质量股票的稀释效应
  - 降低交易成本
  - 提高组合的夏普比率

#### 2. 权重分配优化
- **从等权改为预测值加权**
- **方法**: 
  ```python
  # 将预测值转换为权重
  predicted_weights = predicted_factor.loc[filtered_assets]
  predicted_weights = predicted_weights - predicted_weights.min() + 0.01
  predicted_weights = predicted_weights / predicted_weights.sum()
  ```
- **优势**: 
  - 更好地利用模型的预测信息
  - 预测收益高的股票获得更高权重
  - 提高投资组合的期望收益

---

## 改进的理论依据

### 1. 为什么Gradient Boosting更好？

**非线性关系捕捉**:
- 金融市场中，因子与收益的关系往往是非线性的
- 例如：市值因子可能在小市值和大市值区间有不同的效果
- Gradient Boosting可以通过决策树自动发现这些非线性模式

**因子交互作用**:
- 多个因子组合可能产生协同效应
- 例如：低估值+高盈利能力的股票可能特别优秀
- Gradient Boosting可以学习这些交互效应

**鲁棒性**:
- Huber损失函数对异常值不敏感
- 金融数据常有异常值（如个股停牌、重组等）
- 提高模型在实际应用中的稳定性

### 2. 为什么减少股票数量？

**集中度效应**:
- 根据投资组合理论，在信息比率一定的情况下
- 集中投资于高确信度的标的可以提高夏普比率
- 40只股票已经提供足够的分散化

**降低噪音**:
- 排名靠后的股票（第41-50名）预测确信度较低
- 包含它们可能引入更多噪音而非信号
- 去除低确信度标的可以提高组合质量

### 3. 为什么使用预测值加权？

**信息利用**:
- 等权配置忽略了模型的预测信息
- 预测收益0.1的股票和0.05的股票应该获得不同权重
- 根据预测值加权可以充分利用模型输出

**期望收益最大化**:
- 假设模型预测有效，预测收益高的股票期望收益也高
- 给予高预测收益股票更高权重可以提高组合期望收益
- 在风险可控的前提下提升信息比率

---

## 技术细节

### 模型超参数选择

| 参数 | 值 | 作用 | 选择理由 |
|------|-----|------|----------|
| n_estimators | 150 | 树的数量 | 足够多以学习复杂模式，但不过多导致过拟合 |
| learning_rate | 0.03 | 学习率 | 较低值提高泛化能力，配合更多树使用 |
| max_depth | 5 | 树的最大深度 | 足以捕捉交互作用，但限制复杂度 |
| min_samples_split | 30 | 节点分裂最小样本 | 防止过拟合，确保分裂有统计意义 |
| min_samples_leaf | 15 | 叶节点最小样本 | 防止过拟合，确保预测稳定 |
| subsample | 0.7 | 样本采样比例 | 增加随机性，提高泛化能力 |
| max_features | 'sqrt' | 特征采样策略 | 减少特征相关性影响 |
| loss | 'huber' | 损失函数 | 对异常值鲁棒 |

### 权重计算方法

```python
# Step 1: 获取filtered assets的预测值
predicted_weights = predicted_factor.loc[filtered_assets]

# Step 2: 平移到正值域（确保所有权重为正）
predicted_weights = predicted_weights - predicted_weights.min() + 0.01

# Step 3: 归一化（确保权重之和为1）
predicted_weights = predicted_weights / predicted_weights.sum()
```

这种方法保证了：
1. 所有权重为正（满足做多组合要求）
2. 权重之和为1（满足全额投资要求）
3. 权重大小反映预测收益的相对大小

---

## 预期效果

基于以上改进，预期：

1. **信息比率提升**: 从0.268905提升到更高水平
   - 更好的模型预测能力
   - 更优的投资组合构建

2. **策略稳定性提高**: 
   - 模型对异常值更鲁棒
   - 更多训练数据使模型更稳定

3. **实际可操作性**:
   - 40只股票便于实际操作
   - 保持了合理的分散化

---

## 遵守的约束

✅ **训练数据约束**: 所有训练数据都在start_date之前（使用前4年数据）

✅ **函数接口约束**: `cal_portfolio_weight_series(decision_date, old_portfolio_weight_series)` 接口保持不变

✅ **投资期限约束**: 支持 'M' (月度) 和 'W' (周度) 调仓

✅ **输出格式约束**: 保持与原始代码相同的输出格式（信息比率等指标）

✅ **断点续跑约束**: 保持了simulation_file的断点续跑机制

✅ **聚宽环境约束**: 代码完全兼容聚宽平台的API
